{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Medical LIME Adapter Demo\n",
    "\n",
    "This notebook demonstrates how to use `MedicalLIME` from `medical_lime_adapter.py` to explain predictions from a medical LLM.\n",
    "\n",
    "**Model:** `google/medgemma-4b-it`  \n",
    "**Method:** LIME (Local Interpretable Model-Agnostic Explanations)  \n",
    "**Task:** Multiple Choice Question (MCQ)\n",
    "\n",
    "LIME works by randomly masking words in the prompt, querying the model on each perturbed input, and fitting a local linear model whose coefficients serve as word-level attribution scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers accelerate scikit-learn tqdm hf_xet -q\n",
    "\n",
    "print(\"✓ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project path to Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = \"/content/drive/MyDrive/DATA 298A/sjsu-data298-main\"\n",
    "\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "print(f\"✓ Project path: {project_path}\")\n",
    "print(f\"✓ Path exists: {os.path.exists(project_path)}\")\n",
    "\n",
    "if os.path.exists(project_path):\n",
    "    contents = os.listdir(project_path)\n",
    "    for fname in [\"medical_llm_wrapper.py\", \"medical_lime_adapter.py\"]:\n",
    "        status = \"✓\" if fname in contents else \"⚠️  NOT FOUND\"\n",
    "        print(f\"  {status}  {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrapper and LIME adapter\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "\n",
    "import torch\n",
    "from medical_llm_wrapper import load_medical_llm\n",
    "from medical_lime_adapter import MedicalLIME, visualize_lime_attributions, to_dataframe\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Load MedGemma-4B-IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model — MedGemma auto-converts to float32\n",
    "wrapper = load_medical_llm(\n",
    "    \"google/medgemma-4b-it\",\n",
    "    device=\"cuda\"\n",
    ")\n",
    "wrapper.set_task(\"mcq\")\n",
    "\n",
    "print(\"\\n[Model Information]\")\n",
    "info = wrapper.get_model_info()\n",
    "for key, value in info.items():\n",
    "    if key != \"num_parameters\":\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Define a Medical MCQ Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"A 55-year-old patient presents with persistent cough, hemoptysis, and unintentional weight loss.\n",
    "Chest X-ray shows a mass in the right upper lobe. What is the most likely diagnosis?\n",
    "\n",
    "A) Tuberculosis\n",
    "B) Lung cancer\n",
    "C) Pneumonia\n",
    "D) Pulmonary embolism\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Initialize MedicalLIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = MedicalLIME(\n",
    "    wrapper,\n",
    "    n_samples=300,      # number of perturbed inputs (more = more accurate, but slower)\n",
    "    kernel_width=0.75,  # locality of the linear fit\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"✓ MedicalLIME initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Explain with Auto-Detected Target Class\n",
    "\n",
    "`lime.analyze(prompt)` automatically picks the model's predicted class as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lime.analyze(prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"[LIME Results — Auto Target]\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Prediction        : {result['prediction']}\")\n",
    "print(f\"  Target class      : {result['target_class']}\")\n",
    "print(f\"  P(target)         : {result['target_probability']:.4f}\")\n",
    "print(f\"  All option probs  : {result['all_option_probs']}\")\n",
    "print(f\"  R² (local fit)    : {result['r_squared']:.4f}\")\n",
    "\n",
    "print(\"\\n  Top 5 most influential words (by |attribution|):\")\n",
    "for word, score in result['top_words'][:5]:\n",
    "    direction = \"+\" if score > 0 else \"-\"\n",
    "    print(f\"    [{direction}] '{word}': {score:.4f}\")\n",
    "\n",
    "print(\"\\n  Top positive words (support the predicted class):\")\n",
    "for word, score in result['top_positive_words'][:3]:\n",
    "    print(f\"    '{word}': {score:.4f}\")\n",
    "\n",
    "print(\"\\n  Top negative words (work against the predicted class):\")\n",
    "for word, score in result['top_negative_words'][:3]:\n",
    "    print(f\"    '{word}': {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Explain with Explicit Target Class + Visualization\n",
    "\n",
    "Pass `visualize=True` for a color-coded terminal view.  \n",
    "**Red** = word supports the target class | **Blue** = word works against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_b = lime.analyze(prompt, target_class=\"B\", visualize=True)\n",
    "\n",
    "print(f\"\\nP(B) on original prompt: {result_b['target_probability']:.4f}\")\n",
    "print(f\"R² of local linear fit : {result_b['r_squared']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Inspect Attributions as a DataFrame\n",
    "\n",
    "`to_dataframe()` converts the result into a sorted pandas DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_dataframe(result)\n",
    "print(\"Top 10 most influential words:\")\n",
    "print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Batch Explanation — Multiple Prompts\n",
    "\n",
    "`analyze_batch()` runs LIME over a list of prompts with optional per-prompt target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"\"\"Which vitamin deficiency causes scurvy?\n",
    "A) Vitamin A\n",
    "B) Vitamin B12\n",
    "C) Vitamin C\n",
    "D) Vitamin D\n",
    "\n",
    "Answer:\"\"\",\n",
    "\n",
    "    \"\"\"Which organ produces insulin?\n",
    "A) Liver\n",
    "B) Pancreas\n",
    "C) Kidney\n",
    "D) Spleen\n",
    "\n",
    "Answer:\"\"\"\n",
    "]\n",
    "\n",
    "batch_results = lime.analyze_batch(prompts)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"[Batch LIME Results]\")\n",
    "print(\"=\" * 60)\n",
    "for i, (p, r) in enumerate(zip(prompts, batch_results), 1):\n",
    "    question = p.strip().splitlines()[0]\n",
    "    print(f\"\\nQ{i}: {question}\")\n",
    "    print(f\"  Prediction : {r['prediction']}\")\n",
    "    print(f\"  P(target)  : {r['target_probability']:.4f}\")\n",
    "    print(f\"  R²         : {r['r_squared']:.4f}\")\n",
    "    print(f\"  Top word   : '{r['top_words'][0][0]}' ({r['top_words'][0][1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del wrapper, lime\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"✓ Memory cleaned up\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Medical LIME Demo — Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ]
}
